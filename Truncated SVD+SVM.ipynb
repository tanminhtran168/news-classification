{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification with truncated SVD & SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o51Ubbh4-c1S",
        "outputId": "6a2ea557-3d90-43a9-cbe9-1b961fdbcd92"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW2MLJVT-nAP"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# retrieve X_data, y_data, X_test, y_\n",
        "X_data = pickle.load(open('/content/gdrive/MyDrive/svm content classification/X_data.pkl', 'rb'))\n",
        "y_data = pickle.load(open('/content/gdrive/MyDrive/svm content classification/y_data.pkl', 'rb'))\n",
        "X_test = pickle.load(open('/content/gdrive/MyDrive/svm content classification/X_test.pkl', 'rb'))\n",
        "y_test = pickle.load(open('/content/gdrive/MyDrive/svm content classification/y_test.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMib6L15_YaJ",
        "outputId": "9c23604b-bc01-49cc-e586-5182e21a237c"
      },
      "source": [
        "stopwords = []\n",
        "\n",
        "# open file .txt contains vietnamese stopwords\n",
        "with open ('/content/gdrive/MyDrive/svm content classification/vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
        "  while True:\n",
        "    word = f.readline()\n",
        "    if not word: break\n",
        "    stopwords.append(word[:-1])\n",
        "\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bị', 'bởi', 'cả', 'các', 'cái', 'cần', 'càng', 'chỉ', 'chiếc', 'cho', 'chứ', 'chưa', 'chuyện', 'có', 'có thể', 'cứ', 'của', 'cùng', 'cũng', 'đã', 'đang', 'đây', 'để', 'đến nỗi', 'đều', 'điều', 'do', 'đó', 'được', 'dưới', 'gì', 'khi', 'không', 'là', 'lại', 'lên', 'lúc', 'mà', 'mỗi', 'một cách', 'này', 'nên', 'nếu', 'ngay', 'nhiều', 'như', 'nhưng', 'những', 'nơi', 'nữa', 'phải', 'qua', 'ra', 'rằng', 'rất', 'rồi', 'sau', 'sẽ', 'so', 'sự', 'tại', 'theo', 'thì', 'trên', 'trước', 'từ', 'từng', 'và', 'vẫn', 'vào', 'vậy', 'vì', 'việc', 'với', 'vừa', 'nhận', 'cao', 'nhà', 'quá', 'riêng', 'muốn', 'số', 'thấy', 'hay', 'lần', 'nào', 'bằng', 'biết', 'lớn', 'khác', 'thời gian', 'họ', 'tháng', 'chính', 'nói', 'đi', 'tới', 'tôi', 'làm', 'mới', 'ngày', 'mình', 'còn', 'năm', 'nhất', 'hơn', 'ông', 'anh', 'đến', 'người', 'ở', 'về', 'một', 'trong', 'thực sự', 'ở trên', 'tất cả', 'hầu hết', 'luôn', 'giữa', 'bất kỳ', 'hỏi', 'bạn', 'cô', 'tớ', 'cậu', 'bác', 'chú', 'dì', 'thím', 'mợ', 'bà', 'em', 'thường', 'ai', 'cảm ơn', 'hoặc', 'nh', 'ngoài ra', 'bây giờ', 'hoàn toàn', 'thì thôi', 'ra sao', 'tuy nhiên', 'bây', 'bất', 'cách', 'cảm', 'giờ', 'gian', 'hoàn', 'hầu', 'hết', 'kỳ', 'ngoài', 'nhiên', 'nỗi', 'sao', 'thôi', 'thể', 'thời', 'thực', 'toàn', 'tuy', 'tất', 'ơn', 'của', 'này', 'đã', 'có', 'anh', 'và', 'trong', 'còn']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sDXn7SP_b2j"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# apply TF-IDF technique into vectorizing words\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', stop_words=stopwords)\n",
        "\n",
        "# apply into training data to create vocabulary \n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_data)\n",
        "\n",
        "# TF-IDF X_test\n",
        "X_test_tfidf =  tfidf_vect.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2tYhCKyl99E"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=500, random_state=17)\n",
        "\n",
        "svd.fit(X_train_tfidf)\n",
        "X_data_tfidf_svd = svd.transform(X_train_tfidf)\n",
        "X_test_tfidf_svd = svd.transform(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSZtyB1k_nWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81184b2b-36a7-4410-f05a-5ca9bb83d391"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y_data = encoder.fit_transform(y_data)\n",
        "y_test = encoder.fit_transform(y_test)\n",
        "print(y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[26 26 26 ...  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPof-5VpcaZJ"
      },
      "source": [
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "def create_dnn_model():\n",
        "  input_layer = Input(shape=(500,))\n",
        "  layer = Dense(1024, activation='relu')(input_layer)\n",
        "  layer = Dense(1024, activation='relu')(layer)\n",
        "  layer = Dense(512, activation='relu')(layer)\n",
        "  layer = Dense(256, activation='relu')(layer)\n",
        "  layer = Dense(128, activation='relu')(layer)\n",
        "  layer = Dense(64, activation='relu')(layer)\n",
        "  layer = Dense(32, activation='relu')(layer)\n",
        "  output_layer = Dense(27, activation='softmax')(layer)\n",
        "    \n",
        "  classifier = models.Model(input_layer, output_layer)\n",
        "  classifier.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  classifier.summary()\n",
        "\n",
        "  return classifier\n",
        "\n",
        "def train_model(classifier, X_data, y_data, X_test, y_test, is_neuralnet=False, n_epochs=100):       \n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.1, random_state=42)\n",
        "    \n",
        "    if is_neuralnet:\n",
        "        classifier.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, batch_size=512, verbose=0)\n",
        "        \n",
        "        val_predictions = classifier.predict(X_val)\n",
        "        test_predictions = classifier.predict(X_test)\n",
        "        val_predictions = val_predictions.argmax(axis=-1)\n",
        "        test_predictions = test_predictions.argmax(axis=-1)\n",
        "    else:\n",
        "        classifier.fit(X_train, y_train)\n",
        "    \n",
        "        train_predictions = classifier.predict(X_train)\n",
        "        val_predictions = classifier.predict(X_val)\n",
        "        test_predictions = classifier.predict(X_test)\n",
        "        \n",
        "    print(\"Validation accuracy: \", metrics.accuracy_score(val_predictions, y_val))\n",
        "    print(\"Test accuracy: \", metrics.accuracy_score(test_predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6rCo2Z0neT6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional, Reshape\n",
        "\n",
        "def create_lstm_model():\n",
        "    input_layer = Input(shape=(500,))\n",
        "    \n",
        "    layer = Reshape((10, 50))(input_layer)\n",
        "    layer = LSTM(128, activation='relu')(layer)\n",
        "    layer = Dense(512, activation='relu')(layer)\n",
        "    layer = Dense(512, activation='relu')(layer)\n",
        "    layer = Dense(256, activation='relu')(layer)\n",
        "    layer = Dense(128, activation='relu')(layer)\n",
        "    layer = Dense(64, activation='relu')(layer)\n",
        "    layer = Dense(32, activation='relu')(layer)\n",
        "    \n",
        "    output_layer = Dense(27, activation='softmax')(layer)\n",
        "    \n",
        "    classifier = models.Model(input_layer, output_layer)\n",
        "    \n",
        "    classifier.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    classifier.summary()\n",
        "\n",
        "    return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMldIJ78qL7o",
        "outputId": "fd46fcc3-13a2-495a-fd7b-6f0b8e7ca837"
      },
      "source": [
        "classifier = create_dnn_model()\n",
        "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data, X_test=X_test_tfidf_svd, y_test=y_test, is_neuralnet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 500)]             0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 1024)              513024    \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 27)                891       \n",
            "=================================================================\n",
            "Total params: 2,262,875\n",
            "Trainable params: 2,262,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Validation accuracy:  0.8657858136300417\n",
            "Test accuracy:  0.867008943358728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOENtq4dvcGV",
        "outputId": "dd192e3f-a1f1-4e89-b1fc-a9f3522c0de7"
      },
      "source": [
        "classifier = create_lstm_model()\n",
        "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data, X_test=X_test_tfidf_svd, y_test=y_test, is_neuralnet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 500)]             0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 10, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               91648     \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 27)                891       \n",
            "=================================================================\n",
            "Total params: 595,803\n",
            "Trainable params: 595,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Validation accuracy:  0.7788595271210014\n",
            "Test accuracy:  0.7623385226896323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu4fFlij_7Hf"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "pca = TruncatedSVD(n_components=500, random_state=17)\n",
        "X_train_pca = pca.fit_transform(X_train_tfidf)\n",
        "X_test_pca = pca.transform(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWb0ya6mDwaa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "def train_model(classifier, X_data, y_data):       \n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.1, random_state=42)\n",
        "    \n",
        "  classifier.fit(X_train, y_train)\n",
        "    \n",
        "  # train_predictions = classifier.predict(X_train)\n",
        "  val_predictions = classifier.predict(X_val)\n",
        "        \n",
        "  print(\"Validation accuracy: \", metrics.accuracy_score(val_predictions, y_val))\n",
        "\n",
        "\n",
        "def test_model(classifier, X_test, y_test):\n",
        "\n",
        "  test_predictions = classifier.predict(X_test)\n",
        "  print(\"Test accuracy: \", metrics.accuracy_score(test_predictions, y_test))\n",
        "  print(metrics.classification_report(y_test, test_predictions, digits=27))\n",
        "\n",
        "  return test_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEQbtVili1XF",
        "outputId": "7acddc12-de49-4968-b818-4dac0271d909"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn import svm\n",
        "\n",
        "pca = TruncatedSVD(n_components=1000, random_state=17)\n",
        "X_train_pca = pca.fit_transform(X_train_tfidf)\n",
        "X_test_pca = pca.transform(X_test_tfidf)\n",
        "\n",
        "svm_model = svm.SVC()\n",
        "train_model(svm_model, X_train_pca, y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy:  0.9054242002781642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1QkrW0SLMgX",
        "outputId": "d998750e-2511-4371-9fbf-d5496a34a072"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "n_components = [300, 400, 500, 600, 700]\n",
        "\n",
        "for n_component in n_components:\n",
        "  print(\"Training with\", n_component, \"components: \")\n",
        "  pca = TruncatedSVD(n_components=n_component, random_state=17)\n",
        "  X_train_pca = pca.fit_transform(X_train_tfidf)\n",
        "  X_test_pca = pca.transform(X_test_tfidf)\n",
        "  train_model(svm_model, X_train_pca, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with 300 components: \n",
            "Validation accuracy:  0.8991655076495132\n",
            "Training with 400 components: \n",
            "Validation accuracy:  0.9019471488178025\n",
            "Training with 500 components: \n",
            "Validation accuracy:  0.9054242002781642\n",
            "Training with 600 components: \n",
            "Validation accuracy:  0.9040333796940194\n",
            "Training with 700 components: \n",
            "Validation accuracy:  0.9061196105702365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGnkESJTM_4N",
        "outputId": "ab294717-f6f8-40df-e76a-c87954191d60"
      },
      "source": [
        "# test model with pca 700 principal components\n",
        "test_model(svm_model, X_test_pca, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.9115601192447831\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "                          0  0.930864197530864245777593169 0.927429274292742911178777376 0.929143561306223109141910754       813\n",
            "                          1  0.981723237597911246865578505 0.939999999999999946709294818 0.960408684546615543098369017       400\n",
            "                          2  0.981884057971014523324981838 0.960992907801418438928919841 0.971326164874552033801080597       282\n",
            "                          3  0.997258396161754601116911090 0.993852459016393408042233659 0.995552514539856270303630481      1464\n",
            "                          4  0.983974358974358920271185980 0.959374999999999977795539507 0.971518987341772111143711754       320\n",
            "                          5  0.986876640419947492866015182 0.986876640419947492866015182 0.986876640419947492866015182       381\n",
            "                          6  0.645390070921985858909408762 0.898765432098765471025103579 0.751289989680082648249026533       405\n",
            "                          7  0.983606557377049162127491400 0.913705583756345141033250457 0.947368421052631526357856728       394\n",
            "                          8  0.923339011925042640882566047 0.959292035398230047427148293 0.940972222222222098864108375       565\n",
            "                          9  0.975609756097560953946867812 0.837696335078534026763463771 0.901408450704225372440703268       191\n",
            "                         10  0.824742268041237069908788726 0.571428571428571396850770725 0.675105485232067481504714124       280\n",
            "                         11  0.801546391752577358502662719 0.879773691654879730350558020 0.838840188806473263660734574       707\n",
            "                         12  0.906685236768802194085026258 0.920792079207920832750744466 0.913684210526315765399374413       707\n",
            "                         13  0.870967741935483874549106531 0.906716417910447769479276303 0.888482632541133465764460198       268\n",
            "                         14  0.976271186440678007123494808 0.902821316614420110724381630 0.938110749185667947003253175       319\n",
            "                         15  0.978378378378378377178137271 0.923469387755102011361429959 0.950131233595800539504239168       196\n",
            "                         16  0.857142857142857095276156087 0.931034482758620662856685612 0.892561983471074293916558418        58\n",
            "                         17  0.903508771929824594515423541 0.921288014311270164746758837 0.912311780336581112926808146       559\n",
            "                         18  0.962131837307152903981943837 0.933333333333333348136306995 0.947513812154696100087392097       735\n",
            "                         19  0.612500000000000044408920985 0.686915887850467310471458404 0.647577092511013252540408303       214\n",
            "                         20  0.694736842105263208146936904 0.785714285714285698425385362 0.737430167597765362508255294        84\n",
            "                         21  0.940740740740740766234750936 0.881944444444444419772821675 0.910394265232974841950408518       144\n",
            "                         22  0.969760166840458848191985908 0.902912621359223344086331053 0.935143288084464563425513006      1030\n",
            "                         23  0.886597938144329855703063004 0.867226890756302548624034898 0.876805437553101141290312626       595\n",
            "                         24  0.996441281138790047045006304 0.989399293286219116971835774 0.992907801418439706075957929       283\n",
            "                         25  0.801566579634464759784862053 0.807894736842105221086285383 0.804718217562254367614116290       380\n",
            "                         26  0.882352941176470562112399421 0.894039735099337762314064548 0.888157894736842146166111434       302\n",
            "\n",
            "                   accuracy                      0.911560119244783084724303990     12076\n",
            "                  macro avg  0.898392497942777645825174204 0.892025587340345427200816175 0.892805254712399798400213058     12076\n",
            "               weighted avg  0.917168146352565494261455115 0.911560119244783084724303990 0.912600447643628354121858592     12076\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 19, 15, ...,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}